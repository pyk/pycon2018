{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch for Deep Learning Practitioners\n",
    "\n",
    "## Overview\n",
    "The guide is divided into 2 main parts:\n",
    "\n",
    "1. **Theory**: A brief introduction to PyTorch (concepts + code).\n",
    "2. **Practices**: We will implement, train and deploy a basic feed-forward neural networks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory\n",
    "\n",
    "### What is PyTorch?\n",
    "It’s a Python-based scientific computing package that can be used for:\n",
    "1. A replacement for NumPy to use the power of GPUs\n",
    "2. An open source deep learning platform that provides a seamless path from research prototyping to production deployment.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Components of PyTorch\n",
    "\n",
    "Components of pytorch can be grouped into 3: Low-level API, High-level API and Utilities API.\n",
    "\n",
    "#### Low-level API\n",
    "1. Tensors\n",
    "2. Tensors Operations\n",
    "3. Autograd\n",
    "\n",
    "#### High-level API\n",
    "1. Layers\n",
    "2. Activations\n",
    "3. Loss functions\n",
    "4. Optimizer\n",
    "\n",
    "#### Utilities API\n",
    "1. Data\n",
    "2. Checkpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "`torch.Tensor` are generalizations of a matrix that can be indexed in more than 2 dimensions.\n",
    "\n",
    "#### Creating a Tensors\n",
    "Tensors can be created from Python lists with the `torch.Tensor()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vector\n",
    "vector = [0.0, 1.0, 0.0]\n",
    "torch.Tensor(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix\n",
    "matrix = [[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]]\n",
    "torch.Tensor(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 0.],\n",
       "         [0., 1., 0.]],\n",
       "\n",
       "        [[0., 1., 0.],\n",
       "         [0., 0., 0.]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3D Tensor\n",
    "X = [[[1.0, 0.0, 0.0], [0.0, 1.0, 0.0]], [[0.0, 1.0, 0.0], [0.0, 0.0, 0.0]]]\n",
    "torch.Tensor(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a tensor with random data and the supplied dimensionality with `torch.randn()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1371, -0.7129,  0.1852, -1.8040, -1.6251],\n",
       "         [-0.3541,  0.3962,  2.2637,  0.6944,  0.4783],\n",
       "         [-0.9223, -0.5015,  1.5656, -1.1779, -1.2732],\n",
       "         [-0.7556,  0.7183,  1.3599, -0.9272,  2.1511],\n",
       "         [-1.7306,  0.8332, -2.1668,  0.5663,  0.7291]],\n",
       "\n",
       "        [[ 0.4086,  0.0951, -1.8476,  1.2116, -0.5195],\n",
       "         [-0.9379,  0.2132, -2.0691,  0.9345,  0.9150],\n",
       "         [ 0.2643,  1.6124,  1.1625, -1.4626, -0.5683],\n",
       "         [-1.4458, -0.7793,  1.9571,  0.7178, -1.4030],\n",
       "         [ 1.1021, -0.1194, -0.6543, -0.4118,  0.8679]],\n",
       "\n",
       "        [[ 0.9585,  2.5555,  0.8472, -0.1089,  0.6870],\n",
       "         [ 1.4873, -2.0203, -0.1194, -1.6814,  1.2057],\n",
       "         [ 0.8190,  0.1549,  0.2254, -0.0157, -1.6386],\n",
       "         [-1.3638,  0.4304, -0.4318, -0.9131,  1.2420],\n",
       "         [-0.5192,  0.2369, -0.1555,  2.2627, -0.5231]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn((3, 5, 5))\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create a tensor a tensor filled with the scalar value 0 and specified dimension. Useful for bias initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.]]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases = torch.zeros(size=(3, 1, 3))\n",
    "biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify the tensor data type using `dtype` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(size=(3, 1, 3), dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors Operations\n",
    "\n",
    "#### Mathematical operations\n",
    "You can perform mathematical operations on a tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4710, -0.7448],\n",
       "         [ 0.5936, -0.1468]],\n",
       "\n",
       "        [[-0.7063, -1.7917],\n",
       "         [-0.9366, -2.1349]],\n",
       "\n",
       "        [[-0.2467,  0.6639],\n",
       "         [-0.0783,  0.4409]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(size=(3, 2, 2))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3371,  1.2213],\n",
       "         [-0.0828, -1.4272]],\n",
       "\n",
       "        [[ 1.1819,  2.8166],\n",
       "         [ 0.7510, -0.0315]],\n",
       "\n",
       "        [[ 1.3905,  0.4487],\n",
       "         [ 1.3234,  0.9833]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.randn(size=(3, 2, 2))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1340,  0.4765],\n",
       "         [ 0.5108, -1.5740]],\n",
       "\n",
       "        [[ 0.4756,  1.0249],\n",
       "         [-0.1856, -2.1665]],\n",
       "\n",
       "        [[ 1.1438,  1.1127],\n",
       "         [ 1.2451,  1.4242]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1 = x + y\n",
    "z1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8081, -1.9661],\n",
       "         [ 0.6764,  1.2804]],\n",
       "\n",
       "        [[-1.8881, -4.6083],\n",
       "         [-1.6876, -2.1034]],\n",
       "\n",
       "        [[-1.6372,  0.2152],\n",
       "         [-1.4017, -0.5424]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z2 = x - y\n",
    "z2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1588, -0.9097],\n",
       "         [-0.0492,  0.2095]],\n",
       "\n",
       "        [[-0.8347, -5.0466],\n",
       "         [-0.7034,  0.0673]],\n",
       "\n",
       "        [[-0.3431,  0.2979],\n",
       "         [-0.1036,  0.4335]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z3 = x * y\n",
    "z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.3974, -0.6099],\n",
       "         [-7.1671,  0.1028]],\n",
       "\n",
       "        [[-0.5976, -0.6361],\n",
       "         [-1.2471, 67.7289]],\n",
       "\n",
       "        [[-0.1774,  1.4795],\n",
       "         [-0.0592,  0.4484]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z4 = x / y\n",
    "z4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beyond Mathematical operations\n",
    "You can perform indexing, slicing, joining, mutating operations on a tensors. For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9490,  0.2055, -0.8137])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Indexing\n",
    "x = torch.randn(size=(3,))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9490)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.9490,  0.2055, -0.8137,  0.9490,  0.2055, -0.8137])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining (Concatenation)\n",
    "xx = torch.cat((x, x))\n",
    "xx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [documentation](http://pytorch.org/docs/torch.html) for a complete list of the massive number of operations available to you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autograd\n",
    "\n",
    "Autograd helps you compute the gradient of a tensor operations automatically. It is very useful for back propagation algorithm. \n",
    "\n",
    "For example, suppose:\n",
    "\n",
    "$$s = \\sum_{i} x_{i}w_{i}$$\n",
    "\n",
    "\n",
    "How to compute gradient of s w.r.t element of w?\n",
    "\n",
    "$$\\frac{\\partial s}{\\partial w_{i}}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy. You don’t need to do it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3055, -0.4000, -0.7373,  1.1278,  0.3979, -1.5794,  0.7775,  0.7185,\n",
       "        -0.4478,  2.0922], requires_grad=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(size=(10,), requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.4985, -0.0072,  2.1056,  1.4728, -0.1571, -1.2620, -0.6132, -0.1135,\n",
       "        -0.8372, -0.0665], requires_grad=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.randn(size=(10,), requires_grad=True)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1523,  0.0029, -1.5523,  1.6610, -0.0625,  1.9931, -0.4768, -0.0816,\n",
       "         0.3749, -0.1392], grad_fn=<ThMulBackward>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x * w\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ThMulBackward at 0x10b08b6a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5673, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = z.sum()\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial s}{\\partial w_{i}}=\\frac{\\partial}{\\partial w_{i}}\\sum_{i} x_{i}w_{i}\n",
    "=\\sum_{i} \\frac{\\partial x_{i}w_{i}}{\\partial w_{i}} = x_{i}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3055, -0.4000, -0.7373,  1.1278,  0.3979, -1.5794,  0.7775,  0.7185,\n",
       "        -0.4478,  2.0922])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad.equal(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers\n",
    "PyTorch layers is a python class that represents a neural network layers. It built on top of Tensor, Ops and Autograd.\n",
    "\n",
    "Available layers:\n",
    "1. Convolution Layers\n",
    "2. Pooling Layers\n",
    "3. Padding Layers\n",
    "4. Normalization Layers\n",
    "5. Recurrent layers\n",
    "6. Linear layers\n",
    "7. Dropout Layers\n",
    "8. Embedding Layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear\n",
    "Applies a linear transformation to the incoming tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 50])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "lin = nn.Linear(40, 50)\n",
    "\n",
    "x = torch.randn(size=(10, 40))\n",
    "\n",
    "output = lin(x)\n",
    "output.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the [documentation](https://pytorch.org/docs/stable/nn.html) for a other layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch there are already exists a bunch of pre-defined activation functions that we can use.\n",
    "\n",
    "For example:\n",
    "1. ReLU (`torch.nn.ReLU`)\n",
    "2. Sigmoid (`torch.nn.Sigmoid`)\n",
    "3. Tanh (`torch.nn.Tanh`)\n",
    "4. Softmax (`torch.nn.Softmax`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softmax\n",
    "Applies the Softmax function to an n-dimensional input Tensor rescaling them so that the elements of the n-dimensional output Tensor lie in the range (0,1) and sum to 1.\n",
    "\n",
    "$$x_{i} = \\frac{e^{x_{i}}}{\\sum_{j} e^{x_{j}}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3067,  0.0207,  1.6923, -1.2514, -1.9483])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = nn.Softmax(dim=0)\n",
    "x = torch.randn(size=(5,))\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0966, 0.1340, 0.7131, 0.0376, 0.0187])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = s(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Functions\n",
    "\n",
    "In PyTorch there are exists pre-defined loss function that we can use.\n",
    "\n",
    "For example:\n",
    "1. MSELoss (`torch.nn.MSELoss`)\n",
    "2. CrossEntropyLoss (`torch.nn.CrossEntropyLoss`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Entropy Loss\n",
    "It is useful when training a classification problem with N classes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3084, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "y_hat = torch.randn(3, 5, requires_grad=True)\n",
    "y = torch.empty(3, dtype=torch.long).random_(5)\n",
    "output = loss(y_hat, y)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practices\n",
    "We will build a neural network based a linear classifier to predict what species of flower it is. \n",
    "\n",
    "Step by Step:\n",
    "1. Data Preparation\n",
    "2. Defining a model\n",
    "3. Training a model\n",
    "4. Deploying a model\n",
    "\n",
    "### Data Preparation\n",
    "In this step, we will convert data to tensor then split the data as training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class IrisDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        iris = load_iris()\n",
    "        self.features, raw_labels = iris.data, iris.target\n",
    "        self.labels = []\n",
    "        for i in range(len(raw_labels)):\n",
    "            if raw_labels[i] == 0:\n",
    "                self.labels.append([1, 0, 0])\n",
    "            if raw_labels[i] == 1:\n",
    "                self.labels.append([0, 1, 0])\n",
    "            if raw_labels[i] == 2:\n",
    "                self.labels.append([0, 0, 1])\n",
    "                \n",
    "    def __getitem__(self, index):\n",
    "        feature = torch.Tensor(self.features[index])\n",
    "        label = torch.Tensor(self.labels[index])\n",
    "        sample = {\"feature\": feature, \"label\": label}\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = IrisDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<torch.utils.data.dataset.Subset at 0x10b0ba160>,\n",
       " <torch.utils.data.dataset.Subset at 0x10b0ba128>]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.random_split(dataset, [112, 38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset, testing_dataset = data.random_split(dataset, [112, 38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.Subset at 0x10b0ba390>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a model\n",
    "In this step, we will define our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IrisClassifier, self).__init__()\n",
    "        # Parameters\n",
    "        self.learning_rate = 0.01\n",
    "        \n",
    "        # Define the layers\n",
    "        self.h1_layer = nn.Linear(4, 10)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.h2_layer = nn.Linear(10, 3)\n",
    "        self.softmax = nn.Softmax(dim=0)\n",
    "        \n",
    "        # Define loss functions\n",
    "        self.loss = nn.BCELoss()\n",
    "        \n",
    "        # Define optimizer\n",
    "        self.optimizer = torch.optim.SGD(params=self.parameters(), \n",
    "                                         lr=self.learning_rate)  \n",
    "        \n",
    "    def forward(self, x):\n",
    "        h = self.h1_layer(x)\n",
    "        y_hat = self.softmax(h)\n",
    "        return y_hat\n",
    "    \n",
    "    def backward(self, y_hat, y):\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        # Calculate the loss\n",
    "        loss = self.loss(y_hat, y)\n",
    "        \n",
    "        # Backward\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update parameter\n",
    "        self.optimizer.step()\n",
    "        return loss.data.item()\n",
    "    \n",
    "    def predict(self, x):\n",
    "        y_hat = self.forward(x)\n",
    "        _, predicted = torch.max(y_hat, dim=1)\n",
    "        return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import autograd\n",
    "\n",
    "max_epoch = 50000\n",
    "batch_size = 64\n",
    "loader = data.DataLoader(dataset=dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)\n",
    "\n",
    "# Initialize a model\n",
    "model = IrisClassifier()\n",
    "# Set model to training mode\n",
    "model.train()\n",
    "\n",
    "losses = []\n",
    "for epoch in range(1, max_epoch + 1):\n",
    "    batch_losses = []\n",
    "    for batch in loader:\n",
    "        x = autograd.Variable(batch[\"feature\"])\n",
    "        y = autograd.Variable(batch[\"label\"])\n",
    "\n",
    "        # Forward & Backward\n",
    "        y_hat = model.forward(x)\n",
    "        loss = model.backward(y_hat, y)\n",
    "        batch_losses.append(loss)\n",
    "    sum_loss = 0\n",
    "    for loss in batch_losses:\n",
    "        sum_loss += loss\n",
    "    losses.append(sum_loss/len(batch_losses))\n",
    "\n",
    "# Save the model\n",
    "output_path = \"IrisClassifier.pickle\"\n",
    "torch.save(model.state_dict(), output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
